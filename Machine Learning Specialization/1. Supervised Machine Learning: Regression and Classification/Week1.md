# Gradient descent
![image](https://user-images.githubusercontent.com/91827137/186452707-50f3efc6-0c44-457d-a1e4-889107e6c82c.png)

![image](https://user-images.githubusercontent.com/91827137/186774200-dc4f0020-adaa-40eb-a921-feb6f723d0a3.png)

### Derivative term
![image](https://user-images.githubusercontent.com/91827137/186519938-e51c0afe-446b-4399-877a-8616296be2b4.png)

### Learning Rate
![Screenshot (745)](https://user-images.githubusercontent.com/91827137/186521838-0596106e-2424-4bfa-ab3d-367ed46b8929.png)

![image](https://user-images.githubusercontent.com/91827137/186898289-f906ffa1-5d1a-4aff-b6ee-382709dc1fbf.png)

This explains how gradient descent reach the local minimum while alpha is constant

![Screenshot (758)](https://user-images.githubusercontent.com/91827137/186897858-9f4f23ec-4bcc-40a4-b2b7-e7a1713a0dce.png)

Global Minimum --> The point that has the lowest possible value for the cost function of all possible points(the lowest local minima).

Generally, the locl minima differs depending on where we initialized the parameters w & b. But, in linear regression, the cost function is `(Convex function)`. This means that the squared error cost function with linear regression does not has multiple local minima. This provides a great property which is getting the same local minima whatever was the value of learning rate(Alpha).

![image](https://user-images.githubusercontent.com/91827137/186953260-ac036470-9c0b-435a-8aff-c959658ce926.png)

### Gradient descent in action
![image](https://user-images.githubusercontent.com/91827137/186955272-21afd7cc-a991-43a2-9179-01a2a9dc0d99.png)

### Batch gradient descent
![Screenshot (761)](https://user-images.githubusercontent.com/91827137/186955392-d0c87dba-6102-482b-91b6-3c3817370058.png)
